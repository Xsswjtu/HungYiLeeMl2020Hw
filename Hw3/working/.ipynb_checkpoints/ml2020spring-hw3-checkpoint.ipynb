{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-38bd908d2db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def readfile(path,label):\n",
    "    '''\n",
    "    path: path of images\n",
    "    label: bool, return y or not\n",
    "    '''\n",
    "    files = sorted(os.listdir(path))\n",
    "\n",
    "    X = np.zeros((len(files),128,128,3),dtype=np.uint8)\n",
    "    y = np.zeros((len(files)),dtype=np.uint8)\n",
    "\n",
    "    for i,file in enumerate(files):\n",
    "        img = cv2.imread(os.path.join(path,file))\n",
    "        X[i] = cv2.resize(img,(128,128))\n",
    "        if label:\n",
    "            y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "        return X,y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '../input/ml2020spring-hw3/food-11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Reading data')\n",
    "\n",
    "X_train, y_train = readfile(os.path.join(work_dir,'training'),True)\n",
    "print(f'Size of training data {len(X_train)}')\n",
    "\n",
    "X_val, y_val = readfile(os.path.join(work_dir,'validation'),True)\n",
    "print(f'Size of validation data {len(X_val)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = readfile(os.path.join(work_dir,'testing'),False)\n",
    "print(f'Size of testing data {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class ImgDataSet(Dataset):\n",
    "    def __init__(self,X,y=None,transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        x = self.X[index]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        if self.y is not None:\n",
    "            y = self.y[index]\n",
    "            return x,y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImgDataSet(X_train,y_train,train_transform)\n",
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "val_set = ImgDataSet(X_val,y_val,test_transform)\n",
    "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "        # input [3,128,128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,1,1),   # [64,128,128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),     # [64,64,64]\n",
    "            \n",
    "            nn.Conv2d(64,128,3,1,1), # [128,64,64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),     # [128,32,32]\n",
    "            \n",
    "            nn.Conv2d(128,256,3,1,1), # [256,32,32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),      # [256,16,16]\n",
    "            \n",
    "            nn.Conv2d(256,512,3,1,1), # [512,16,16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),      # [512,8,8]\n",
    "\n",
    "            nn.Conv2d(512,512,3,1,1), # [512,8,8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2,0),      # [512,4,4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4,1024),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,11)\n",
    "        )        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(data[0].cuda())\n",
    "        batch_loss = loss(train_pred,data[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(),axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred,data[1].cuda())\n",
    "            \n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        train_acc /= train_set.__len__()\n",
    "        train_loss /= train_set.__len__()\n",
    "        val_acc /= val_set.__len__()\n",
    "        val_loss /= val_set.__len__()\n",
    "        \n",
    "        cost_time = time.time() - start_time\n",
    "        print(f'[{epoch+1:03d}/{num_epoch:03d}] {cost_time:2.2f} sec(s) Train Acc: {train_acc:3.6f} Loss: {train_loss:3.6f} | Val Acc: {val_acc:3.6f} Loss: {val_loss:3.6f}')\n",
    "\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_loss_history.append(train_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "        val_loss_history.append(val_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(train_acc_history)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num),train_acc_history,range(num),val_acc_history)\n",
    "plt.legend(['train','val'])\n",
    "plt.title('acc')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num),train_loss_history,range(num),val_loss_history)\n",
    "plt.legend(['train','val'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从val set上看，这个模型表现是比较不错的。现在用所有的数据来train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = np.concatenate((X_train,X_val),axis=0)\n",
    "y_train_val = np.concatenate((y_train,y_val),axis=0)\n",
    "\n",
    "train_val_set = ImgDataSet(X_train_val,y_train_val,train_transform)\n",
    "train_val_loader = DataLoader(train_val_set,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "train_val_acc_history = []\n",
    "train_val_loss_history = []\n",
    "\n",
    "num_epoch = 5\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i,data in enumerate(train_val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(data[0].cuda())\n",
    "        batch_loss = loss(train_pred,data[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(),axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    train_acc /= train_val_set.__len__()\n",
    "    train_loss /= train_val_set.__len__()\n",
    "\n",
    "    cost_time = time.time() - start_time\n",
    "    print(f'[{epoch+1:03d}/{num_epoch:03d}] {cost_time:2.2f} sec(s) Train Acc: {train_acc:3.6f} Loss: {train_loss:3.6f}')\n",
    "\n",
    "    train_val_acc_history.append(train_acc)\n",
    "    train_val_loss_history.append(train_loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(train_val_acc_history)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num),train_val_acc_history)\n",
    "plt.title('acc')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num),train_val_loss_history)\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = 'model_hw3.pth'\n",
    "\n",
    "torch.save(model.state_dict(),model_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier().cuda()\n",
    "# model.load_state_dict(torch.load('../input/model/model_hw3.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImgDataSet(X_test,transform=test_transform)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(test_loader):\n",
    "        test_pred = model(data.cuda())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(),axis=1)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict_hw3.csv','w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i,y in enumerate(prediction):\n",
    "        f.write(f'{i},{y}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
