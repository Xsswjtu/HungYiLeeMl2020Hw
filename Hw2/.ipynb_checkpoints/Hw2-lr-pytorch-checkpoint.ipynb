{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DataReader import DataReader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "dr = DataReader(val_size=0.1)\n",
    "dr.read()\n",
    "X_train, X_val, X_test, y_train, y_val = dr.data()\n",
    "\n",
    "# X_train = np.concatenate((np.ones((X_train.shape[0],1),dtype=np.int64),X_train),axis=1)\n",
    "# X_val = np.concatenate((np.ones((X_val.shape[0],1),dtype=np.int64),X_val),axis=1)\n",
    "# X_test = np.concatenate((np.ones((X_test.shape[0],1),dtype=np.int64),X_test),axis=1)\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48830, 510]),\n",
       " tensor([[ 0.4927, -1.0007, -0.1820, -0.1781, -0.2538],\n",
       "         [-0.2656,  0.9993, -0.1820, -0.1781, -0.2538],\n",
       "         [-0.6989,  0.9993, -0.1820, -0.1781, -0.2538],\n",
       "         [ 0.8177, -1.0007, -0.1820, -0.1781, -0.2538],\n",
       "         [-0.3198,  0.9993, -0.1820, -0.1781, -0.2538]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_train[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_input_features):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.Line = nn.Linear(n_input_features,1)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return torch.sigmoid(self.Line(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X_train.shape[1])\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "model_pth = 'model.pth'\n",
    "\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(decay):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.3,weight_decay=decay)\n",
    "    \n",
    "    epoches = 10000\n",
    "    history = {\n",
    "        'train loss':[],\n",
    "        'val loss':[],\n",
    "        'train acc':[],\n",
    "        'val acc':[]\n",
    "    }\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred,y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(X_val)\n",
    "\n",
    "            loss_val = loss_fn(y_pred_val,y_val)\n",
    "\n",
    "            train_acc = (y_pred.round().eq(y_train).sum()/float(y_train.shape[0])).item()\n",
    "            val_acc = (y_pred_val.round().eq(y_val).sum()/float(y_val.shape[0])).item()\n",
    "\n",
    "            history['train acc'].append(train_acc)\n",
    "            history['val acc'].append(val_acc)\n",
    "\n",
    "            history['train loss'].append(loss.item())\n",
    "            history['val loss'].append(loss_val.item())\n",
    "\n",
    "            if val_acc > best_accuracy:\n",
    "                print(f'better accuracy found:{val_acc} train acc:{train_acc} deacy:{decay}, model saved!')\n",
    "                best_accuracy = val_acc\n",
    "                torch.save(model.state_dict(),model_pth)\n",
    "\n",
    "#         if (epoch+1) % (epoches/10) == 0:\n",
    "#             print(f'epoch {epoch+1} train loss:{loss.item()} val loss:{loss_val.item()} train acc:{train_acc} val_acc:{val_acc}')\n",
    "\n",
    "\n",
    "    plt.plot(range(epoches),history['train loss'],range(epoches),history['val loss'])\n",
    "    plt.legend(['train','val'])\n",
    "    plt.title('loss')\n",
    "    plt.savefig(f'loss_{decay}.png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(epoches),history['train acc'],range(epoches),history['val acc'])\n",
    "    plt.legend(['train','val'])\n",
    "    plt.title('accuracy')\n",
    "    plt.savefig(f'acc_{decay}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best_accuracy' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-894e39d186cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdecays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-8a38310415fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(decay)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'better accuracy found:{val_acc} train acc:{train_acc} deacy:{decay}, model saved!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'best_accuracy' referenced before assignment"
     ]
    }
   ],
   "source": [
    "decays = [0,0.001,0.003,0.01,0.03,0.1,0.3,1]\n",
    "for d in decays:\n",
    "    train(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    p = np.round(model(X_test).detach()).numpy().astype(np.int)\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'id':list(range(X_test.shape[0])),\n",
    "                       'label':p.flatten()})\n",
    "\n",
    "    df.to_csv('result.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.abs(list(model.parameters())[0].detach().numpy()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argsort(theta)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital gains\t0.8868908286094666\n",
      "weeks worked in year\t0.5790798664093018\n",
      "dividends from stocks\t0.5659188032150269\n",
      "age\t0.45645272731781006\n",
      " Trinadad&Tobago.2\t0.3527606725692749\n",
      "num persons worked for employer\t0.3379727900028229\n",
      " Masters degree(MA MS MEng MEd MSW MBA)\t0.30041295289993286\n",
      " Female\t0.25408831238746643\n",
      " Male\t0.25408828258514404\n",
      " Trinadad&Tobago\t0.22973871231079102\n"
     ]
    }
   ],
   "source": [
    "for i in ind[0:10]:\n",
    "    print(f'{dr.columns[i]}\\t{theta[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
