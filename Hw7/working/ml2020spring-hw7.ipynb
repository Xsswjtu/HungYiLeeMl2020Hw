{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os,time\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_log = open('log.log','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLogFile(str,end_str='\\n'):\n",
    "    print(str,end=end_str)\n",
    "    print(str,end=end_str,file=fn_log)\n",
    "    fn_log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    '''\n",
    "    在这个Net里面 我们会使用 Depthwise & Pointwise Convolution Layer 来叠 model\n",
    "    你会发现,将原本的Convolution Layer 换成 Dw & Pw 后, Acurracy 通常不会降低很多\n",
    "    \n",
    "    另外,取名为 StudentNet 是因为这个 Model 后续要做 Knowledge Distillation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,base=16,width_mult=1):\n",
    "        '''\n",
    "        Args:\n",
    "            base: 这个model一开始的ch数量 每过一层都会*2 直到base*16为止\n",
    "            width_mult: 为了之后的 Network Pruning使用,在base*8 chs的Layer上会 * width_mult代表剪枝后的ch数量\n",
    "        '''\n",
    "        super(StudentNet,self).__init__()\n",
    "        multiplier = [1,2,4,8,16,16,16,16]\n",
    "        \n",
    "        # bandwidth: 每一个layer所使用的channel数量\n",
    "        bandwidth = [base * m for m in multiplier]\n",
    "        \n",
    "        # 我们只是Pruning第三层以后的layer  ??? why not pruning layer 8\n",
    "        for i in range(3,7):\n",
    "            bandwidth[i] = int(bandwidth[i]*width_mult)\n",
    "            \n",
    "        self.cnn = nn.Sequential(\n",
    "            # 第一层我们通常不做拆解Convolution Layer\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3,bandwidth[0],3,1,1),\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                nn.ReLU6(),\n",
    "                nn.MaxPool2d(2,2,0)\n",
    "            ),\n",
    "            \n",
    "            # 接下来开始pruning\n",
    "            nn.Sequential(\n",
    "                # DW\n",
    "                nn.Conv2d(bandwidth[0],bandwidth[0],3,1,1,groups=bandwidth[0]),\n",
    "                # Batch Normalization\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                # RELU6 是限制neural最小只能到0,最大只能到6。MobileNet都是用的RELU6\n",
    "                # 使用RELU6是因为如果数字过大时,不方便压缩到float16,也不方便之后的parameters quantization,所以用R\n",
    "                nn.ReLU6(),\n",
    "                # PW\n",
    "                nn.Conv2d(bandwidth[0],bandwidth[1],1),\n",
    "                # 过完PW后不需要再过RELU,经验上PW+RELU效果都会变差\n",
    "                # 每过完一个block就进行down sampling\n",
    "                nn.MaxPool2d(2,2,0)\n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[1],bandwidth[1],3,1,1,groups=bandwidth[1]),\n",
    "                nn.BatchNorm2d(bandwidth[1]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[1],bandwidth[2],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[2],bandwidth[2],3,1,1,groups=bandwidth[2]),\n",
    "                nn.BatchNorm2d(bandwidth[2]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[2],bandwidth[3],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[3],bandwidth[3],3,1,1,groups=bandwidth[3]),\n",
    "                nn.BatchNorm2d(bandwidth[3]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[3],bandwidth[4],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[4],bandwidth[4],3,1,1,groups=bandwidth[4]),\n",
    "                nn.BatchNorm2d(bandwidth[4]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[4],bandwidth[5],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),            \n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[5],bandwidth[5],3,1,1,groups=bandwidth[5]),\n",
    "                nn.BatchNorm2d(bandwidth[5]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[5],bandwidth[6],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),            \n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[6],bandwidth[6],3,1,1,groups=bandwidth[6]),\n",
    "                nn.BatchNorm2d(bandwidth[6]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[6],bandwidth[7],1),\n",
    "                nn.MaxPool2d(2,2,0),                \n",
    "            ),            \n",
    "\n",
    "            # 这里我采用 global average pooling,\n",
    "            # 如果输入的图片不一样 会因为 global average pooling 压成一样的形状,这样后面作FC就不会冲突\n",
    "            # ？？？ 它这里没有采用对 dataset 做 resize transform\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            # 这里我们直接 project 到11纬来输出答案\n",
    "            nn.Linear(bandwidth[7],11),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0],-1)\n",
    "        return self.fc(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
    "    # 一般的Cross Entropy\n",
    "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
    "    return hard_loss + soft_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folderName, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
    "            try:\n",
    "                # Get classIdx by parsing image path\n",
    "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
    "            except:\n",
    "                # if inference mode (there's no answer), class_idx default 0\n",
    "                class_idx = 0\n",
    "\n",
    "            self.data.append(img_path)\n",
    "            self.label.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "#         return 100\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path)\n",
    "        # Get File Descriptor\n",
    "        image_fp = image.fp\n",
    "        image.load()\n",
    "        # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "        image_fp.close()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label[idx]\n",
    "\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(mode='training', batch_size=32):\n",
    "\n",
    "    assert mode in ['training', 'testing', 'validation']\n",
    "\n",
    "    dataset = MyDataset(\n",
    "        f'../input/ml2020spring-hw7/food-11/{mode}',\n",
    "        transform=trainTransform if mode == 'training' else testTransform)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(mode == 'training'),\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(mode='training',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = get_dataloader(mode='validation',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net = models.resnet18(pretrained=False,num_classes=11).to(device)\n",
    "\n",
    "student_net = StudentNet(base=16).to(device)\n",
    "\n",
    "teacher_net.load_state_dict(torch.load(f'../input/hw7-model/teacher_resnet18.bin',map_location=device))\n",
    "\n",
    "optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_loader,update=True,alpha=0.5):\n",
    "    total_num,total_hit,total_loss = 0,0,0\n",
    "    for now_step, batch_data in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, hard_labels = batch_data\n",
    "#         inputs = inputs.to(device)\n",
    "        inputs = inputs.to(torch.device('cuda'))\n",
    "        teacher_net.cuda()\n",
    "        student_net.cuda()\n",
    "        hard_labels = torch.LongTensor(hard_labels).to(device)\n",
    "        # 因为 TecherNet 没有要做 backprop 所以 我们要用 torch.no_grad \n",
    "        # 告诉torch不要去存储中间值（用来做 backprop）以浪费内存\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(inputs)\n",
    "            \n",
    "        if update:\n",
    "            logits = student_net(inputs) \n",
    "            # 使用我們之前所寫的融合soft label&hard label的loss。\n",
    "            # T=20是原始論文的參數設定。\n",
    "            loss = loss_fn_kd(logits,hard_labels,soft_labels,20,alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            # 只是算validation acc的話，就開no_grad節省空間。\n",
    "            with torch.no_grad():\n",
    "                logits = student_net(inputs) \n",
    "                loss = loss_fn_kd(logits,hard_labels,soft_labels,20,alpha)\n",
    "\n",
    "        total_hit += torch.sum(torch.argmax(logits,dim=1) == hard_labels).item()\n",
    "        total_num += len(inputs)\n",
    "    \n",
    "        total_loss += loss.item()*len(inputs)\n",
    "        print('Nowstep {}/{}: loss: {:6.4f}, acc {:6.4f} device:{}'.format(\n",
    "            now_step+1, len(data_loader), total_loss/total_num, total_hit/total_num, device),end='\\r')\n",
    "    return total_loss/total_num, total_hit/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TeacherNet 永远都是eval模式\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "\n",
    "# 从之前训练的模型基础上开始训练模型\n",
    "\n",
    "# student_net.load_state_dict(torch.load('../input/hw7-model/student_model.bin'))\n",
    "\n",
    "for epoch in range(200):\n",
    "    start = time.time()\n",
    "    student_net.train()\n",
    "    train_loss,train_acc = run_epoch(train_loader,update=True)\n",
    "    student_net.eval()\n",
    "    val_loss,val_acc = run_epoch(valid_loader,update=False)\n",
    "    \n",
    "    # 存下最好的 model\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(),'student_model.bin')\n",
    "\n",
    "    printLogFile('Epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}, seconds used {:6.4f}'.format(\n",
    "        epoch, train_loss, train_acc, val_loss, val_acc, time.time()-start))\n",
    "\n",
    "    fn_log.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval the student_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_net.load_state_dict(torch.load('../input/hw7-model/student_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nowstep 4/4: loss: 8.2315, acc 0.6400 device:cuda\n",
      "Trained student_net loss:8.2315 acc:0.6400\n"
     ]
    }
   ],
   "source": [
    "student_net.eval()\n",
    "val_loss,val_acc = run_epoch(valid_loader,update=False)\n",
    "\n",
    "printLogFile(f'\\nTrained student_net loss:{val_loss:6.4f} acc:{val_acc:6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original cost: 1046701 bytes\n"
     ]
    }
   ],
   "source": [
    "printLogFile(f\"\\noriginal cost: {os.stat('../input/hw7-model/student_model.bin').st_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load('../input/hw7-model/student_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32-bit Tensor --> 16-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16-bit cost: 522958 bytes\n",
      "Nowstep 4/4: loss: 8.2303, acc 0.6400 device:cuda\n",
      "Trained student_net loss:8.2303 acc:0.6400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def encode16(params,fname):\n",
    "    '''\n",
    "    将params压缩成16bit后输出到fname\n",
    "    \n",
    "    Args:\n",
    "        params: model`s state_dict\n",
    "        fname: output file`s name\n",
    "    '''\n",
    "    custom_dict = {}\n",
    "    for (name,param) in params.items():\n",
    "        param = np.float64(param.cpu().numpy())\n",
    "        # some item is just a number, need not to be compressed\n",
    "        if type(param) == np.ndarray:\n",
    "            custom_dict[name] = np.float16(param)\n",
    "        else:\n",
    "            custom_dict[name] = param\n",
    "    pickle.dump(custom_dict,open(fname,'wb'))\n",
    "    \n",
    "def decode16(fname):\n",
    "    '''\n",
    "    从fname读取各个param 将其从16bit还原回torch.tensor 后存如 state_dict \n",
    "    \n",
    "    Args:\n",
    "        fname: file name\n",
    "    '''\n",
    "    params = pickle.load(open(fname,'rb'))\n",
    "    custom_dict = {}\n",
    "    for (name,param) in params.items():\n",
    "        param = torch.tensor(param)\n",
    "        custom_dict[name] = param\n",
    "    return custom_dict\n",
    "\n",
    "encode16(params,'16_bit_model.pkl')\n",
    "\n",
    "printLogFile(f\"\\n16-bit cost: {os.stat('16_bit_model.pkl').st_size} bytes\")\n",
    "\n",
    "student_net.load_state_dict(decode16('16_bit_model.pkl'))\n",
    "\n",
    "student_net.eval()\n",
    "val_loss,val_acc = run_epoch(valid_loader,update=False)\n",
    "\n",
    "printLogFile(f'\\n16-bit Trained student_net loss:{val_loss:6.4f} acc:{val_acc:6.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32-bit Tensor -> 8-bit (OPTIONAL)\n",
    "\n",
    "這邊提供轉成8-bit的方法，僅供大家參考。\n",
    "因為沒有8-bit的float，所以我們先對每個weight記錄最小值和最大值，進行min-max正規化後乘上$2^8-1$在四捨五入，就可以用np.uint8存取了。\n",
    "\n",
    "$W' = round(\\frac{W - \\min(W)}{\\max(W) - \\min(W)} \\times (2^8 - 1)$)\n",
    "\n",
    "\n",
    "\n",
    "> 至於能不能轉成更低的形式，例如4-bit呢? 當然可以，待你實作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8-bit cost: 268471 bytes\n",
      "Nowstep 4/4: loss: 8.3283, acc 0.6200 device:cuda\n",
      "Trained student_net loss:8.3283 acc:0.6200\n"
     ]
    }
   ],
   "source": [
    "def encode8(params,fname):\n",
    "    '''\n",
    "    将params压缩成8bit后输出到fname\n",
    "    \n",
    "    Args:\n",
    "        params: model`s state_dict\n",
    "        fname: output file`s name\n",
    "    '''\n",
    "    custom_dict = {}\n",
    "    for (name,param) in params.items():\n",
    "        param = np.float64(param.cpu().numpy())\n",
    "        # some item is just a number, need not to be compressed\n",
    "        if type(param) == np.ndarray:\n",
    "            min_val = np.min(param)\n",
    "            max_val = np.max(param)\n",
    "            param = np.round((param-min_val)/(max_val-min_val)*255)\n",
    "            param = np.uint8(param)\n",
    "            custom_dict[name] = (min_val,max_val,param)\n",
    "        else:\n",
    "            custom_dict[name] = param\n",
    "    pickle.dump(custom_dict,open(fname,'wb'))\n",
    "    \n",
    "def decode8(fname):\n",
    "    '''\n",
    "    从fname读取各个param 将其从8bit还原回torch.tensor 后存如 state_dict \n",
    "    \n",
    "    Args:\n",
    "        fname: file name\n",
    "    '''\n",
    "    params = pickle.load(open(fname,'rb'))\n",
    "    custom_dict = {}\n",
    "    for (name,param) in params.items():\n",
    "        if type(param) == tuple:\n",
    "            min_val,max_val,param = param\n",
    "            param = np.float64(param)\n",
    "            param = (param / 255 * (max_val - min_val)) + min_val\n",
    "\n",
    "        param = torch.tensor(param)\n",
    "        custom_dict[name] = param\n",
    "    return custom_dict\n",
    "\n",
    "encode8(params,'8_bit_model.pkl')\n",
    "\n",
    "printLogFile(f\"\\n8-bit cost: {os.stat('8_bit_model.pkl').st_size} bytes\")\n",
    "\n",
    "student_net.load_state_dict(decode8('8_bit_model.pkl'))\n",
    "\n",
    "student_net.eval()\n",
    "val_loss,val_acc = run_epoch(valid_loader,update=False)\n",
    "\n",
    "printLogFile(f'\\n8-bit Trained student_net loss:{val_loss:6.4f} acc:{val_acc:6.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(mode='testing',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4\r"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for i,data in enumerate(test_loader):\n",
    "    inputs,_ = data\n",
    "    inputs = inputs.to(device)\n",
    "    student_net.to(device)\n",
    "    student_net.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = student_net(inputs)\n",
    "        logits = torch.argmax(logits,dim=1).cpu().numpy().tolist()\n",
    "        pred += logits\n",
    "    print(f'{i+1}/{len(test_loader)}',end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id':list(range(len(pred))),'value':pred})\n",
    "\n",
    "df.to_csv('predict.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
