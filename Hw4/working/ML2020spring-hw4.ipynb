{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_file_label = '../input/ml2020spring-hw4/training_label.txt'\n",
    "train_file_nolabel = '../input/ml2020spring-hw4/training_nolabel.txt'\n",
    "test_file = '../input/ml2020spring-hw4/testing_data.txt'\n",
    "\n",
    "w2v_path = '../input/w2v-model/w2v.model'\n",
    "model_path = 'hw4.model'\n",
    "\n",
    "sen_len = 20\n",
    "fix_embedding = True\n",
    "batch_size = 128\n",
    "epoch = 20\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    '''\n",
    "    class for reading data\n",
    "    '''\n",
    "    def __init__(self,train_file_label = 'data/training_label.txt',\n",
    "                 train_file_nolabel = 'data/training_nolabel.txt',\n",
    "                 test_file = 'data/testing_data.txt'):\n",
    "        self.train_file_label = train_file_label\n",
    "        self.train_file_nolabel = train_file_nolabel\n",
    "        self.test_file = test_file\n",
    "    \n",
    "    def train_data_label(self):\n",
    "        return self.load_train_data(self.train_file_label,labeled=True)\n",
    "\n",
    "    def train_data_nolabel(self):\n",
    "        return self.load_train_data(self.train_file_nolabel,labeled=False)\n",
    "\n",
    "    def test_data(self):\n",
    "        return self.load_test_data(self.test_file)\n",
    "    \n",
    "    def load_train_data(self,path,labeled=False):\n",
    "        with open(path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip('\\n').split(' ') for line in lines]\n",
    "            if labeled:\n",
    "                X = [line[2:] for line in lines]\n",
    "                Y = [line[0] for line in lines]\n",
    "                return X,Y\n",
    "            else:\n",
    "                X = lines\n",
    "                return X\n",
    "\n",
    "    def load_test_data(self,path):\n",
    "        with open(path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip('\\n').split(',')[1:] for line in lines[1:]]\n",
    "            X = [''.join(line).split(' ') for line in lines]\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "dr = DataReader(train_file_label=train_file_label,train_file_nolabel=train_file_nolabel,test_file=test_file)\n",
    "X_train_label,Y_train_label = dr.train_data_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self,sentences,sen_len,w2v_path):\n",
    "        self.sentences = sentences\n",
    "        self.sen_len = sen_len\n",
    "        self.embedding = Word2Vec.load(w2v_path)\n",
    "        self.embedding_dim = self.embedding.vector_size\n",
    "        self.idx2word = []\n",
    "        self.word2idx = {}\n",
    "        self.embedding_matrix = []\n",
    "\n",
    "    def random_vector(self):\n",
    "        vector = torch.empty(1,self.embedding_dim)\n",
    "        torch.nn.init.uniform_(vector)\n",
    "        return vector\n",
    "        \n",
    "    def add_embedding(self,word):\n",
    "        # add word into embedding and give it random representation vector\n",
    "        # word will be '<PAD>' or '<UNK>' ONLY\n",
    "        vector = self.random_vector()\n",
    "        self.word2idx[word] = len(self.word2idx)\n",
    "        self.idx2word.append(vector)\n",
    "        self.embedding_matrix = torch.cat((self.embedding_matrix,vector),0)\n",
    "        \n",
    "    def make_embedding(self):\n",
    "        print('Get embedding ...')\n",
    "        for i, word in enumerate(self.embedding.wv.vocab):\n",
    "#             print(f'get words #{i+1}',end='\\r')\n",
    "            self.word2idx[word] = len(self.idx2word)\n",
    "            self.idx2word.append(word)\n",
    "            self.embedding_matrix.append(self.embedding[word])\n",
    "        print('')\n",
    "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
    "        self.add_embedding('<PAD>')\n",
    "        self.add_embedding('<UNK>')\n",
    "        print(f'total words: {len(self.embedding_matrix)}')\n",
    "        return self.embedding_matrix\n",
    "    \n",
    "    def pad_sequence(self,sentence):\n",
    "        # make all sentences having the save length\n",
    "        if len(sentence) > self.sen_len:\n",
    "            sentence = sentence[:self.sen_len]\n",
    "        else:\n",
    "            pad_len = self.sen_len - len(sentence)\n",
    "            for _ in range(pad_len):\n",
    "                sentence.append(self.word2idx['<PAD>'])\n",
    "        assert len(sentence) == self.sen_len\n",
    "        return sentence\n",
    "    \n",
    "    def sentence_word2idx(self):\n",
    "        # change words in sentence to idx\n",
    "        sentence_list = []\n",
    "        for i,sen in enumerate(self.sentences):\n",
    "#             print(f'sentence count #{i+1}', end='\\r')\n",
    "            sentence_idx = []\n",
    "            for word in sen:\n",
    "                if word in self.word2idx.keys():\n",
    "                    sentence_idx.append(self.word2idx[word])\n",
    "                else:\n",
    "                    sentence_idx.append(self.word2idx['<UNK>'])\n",
    "            # make all sentences having the same length\n",
    "            sentence_idx = self.pad_sequence(sentence_idx)\n",
    "            sentence_list.append(sentence_idx)\n",
    "        return torch.LongTensor(sentence_list)\n",
    "\n",
    "    def labels_to_tensor(self,labels):\n",
    "        y = [int(label) for label in labels]\n",
    "        return torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get embedding ...\n",
      "\n",
      "total words: 55779\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "preprocess = Preprocess(X_train_label,sen_len=sen_len,w2v_path=w2v_path)\n",
    "embedding = preprocess.make_embedding()\n",
    "train_x = preprocess.sentence_word2idx()\n",
    "train_y = preprocess.labels_to_tensor(Y_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.data = X\n",
    "        self.label = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.data[index],self.label[index]\n",
    "        else:\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train valid set\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_x[:180000],train_x[180000:],train_y[:180000],train_y[180000:]\n",
    "# X_train,X_val,y_train,y_val = train_x[:1800],train_x[1800:2000],train_y[:1800],train_y[1800:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "train_dataset = TwitterDataset(X_train,y_train)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "\n",
    "val_dataset = TwitterDataset(X_val,y_val)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model define\n",
    "\n",
    "class LSTM_Net(nn.Module):\n",
    "    '''\n",
    "    RRN\n",
    "    '''\n",
    "    def __init__(self,embedding,hidden_dim,num_layers,\n",
    "                dropout=0.5,fix_embedding=True):\n",
    "        super(LSTM_Net,self).__init__()\n",
    "        self.embedding_dim = embedding.size(1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # make embedding layer\n",
    "        self.embedding = nn.Embedding(embedding.size(0),embedding.size(1))\n",
    "        self.embedding.weight = nn.Parameter(embedding)\n",
    "        self.embedding.weight.requires_grad = False if fix_embedding else True\n",
    "        \n",
    "        # define LSTM layer\n",
    "        self.lstm = nn.LSTM(self.embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        \n",
    "        # define classifier, which is a fc nn\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print('input data: ',type(x),x.shape)\n",
    "        inputs = self.embedding(x)\n",
    "        #print('after embedding: ',type(inputs),inputs.shape)\n",
    "        x, _ = self.lstm(inputs,None)\n",
    "        #print('after lstm: ',type(x),x.shape)\n",
    "        x = x[:,-1,:]\n",
    "        #print('after -1: ',x.shape)\n",
    "        out = self.classifier(x)\n",
    "        #print('after classifier: ', out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Net(embedding=embedding,hidden_dim=150,num_layers=1,dropout=0.5,fix_embedding=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian method\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluation(output,labels):\n",
    "    '''\n",
    "    return the number of right predictions\n",
    "    '''\n",
    "    output[output>=0.5] = 1\n",
    "    output[output<0.5] = 0\n",
    "    return torch.sum(torch.eq(output,labels)).item()\n",
    "\n",
    "def training(batch_size,n_epoch,lr,train,valid,model,model_path,device):\n",
    "    start = time.time()\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad==True)\n",
    "    print(f'Parameters total num:{total} trainable:{trainable}')\n",
    "    \n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "    t_len, v_len = (len(train),len(valid))\n",
    "    total_loss, total_acc, best_acc = 0,0,0\n",
    "    \n",
    "    train_loss_history =[]\n",
    "    train_acc_history = []\n",
    "\n",
    "    val_loss_history =[]\n",
    "    val_acc_history = []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss,total_acc = 0,0\n",
    "        for i,(inputs,labels) in enumerate(train):\n",
    "            inputs = inputs.to(device,dtype=torch.long)\n",
    "            labels = labels.to(device,dtype=torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            correct = evaluation(outputs,labels)\n",
    "            total_acc += (correct/batch_size)\n",
    "            total_loss += loss.item()\n",
    "            print('Epoch {} {}/{} acc {:.3f} loss {:.5f}'.format(epoch+1,i+1,t_len,\n",
    "                                                         correct*100/batch_size,total_loss),end='\\r')\n",
    "        print('\\nTrain total acc {:.3f} total loss {:.5f}'.format(total_acc*100/t_len,total_loss/t_len))\n",
    "        \n",
    "        train_loss_history.append(total_loss/t_len)\n",
    "        train_acc_history.append(total_acc*100/t_len)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss, total_acc = 0,0\n",
    "            for i,(inputs,labels) in enumerate(valid):\n",
    "                inputs = inputs.to(device,dtype=torch.long)\n",
    "                labels = labels.to(device,dtype=torch.float)\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "                loss = criterion(outputs,labels)\n",
    "                correct = evaluation(outputs,labels)\n",
    "                total_acc += (correct/batch_size)\n",
    "                total_loss += loss.item()\n",
    "            print('\\nValid total acc {:.3f} total loss {:.5f}'.format(total_acc*100/v_len,total_loss/v_len))\n",
    "            \n",
    "            if total_acc > best_acc:\n",
    "                best_acc = total_acc\n",
    "                torch.save(model,model_path)\n",
    "                print(f'Saving model with acc: {total_acc*100/v_len}')\n",
    "\n",
    "        val_loss_history.append(total_loss/v_len)\n",
    "        val_acc_history.append(total_acc*100/v_len)\n",
    "\n",
    "        print('-------------------------------------------------------------------------')\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(n_epoch),train_loss_history,range(n_epoch),val_loss_history)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(n_epoch),train_acc_history,range(n_epoch),val_acc_history)\n",
    "    plt.legend(['val','val'])\n",
    "    plt.title('acc')\n",
    "\n",
    "    print('======================================================================')\n",
    "    print(f'Training used time: {time.time()-start:2.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(batch_size=batch_size,\n",
    "        n_epoch=epoch,\n",
    "        lr=lr,\n",
    "        train=train_loader,\n",
    "        valid=val_loader,\n",
    "        model=model,\n",
    "        model_path=model_path,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get embedding ...\n",
      "\n",
      "total words: 55779\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "# Reading data\n",
    "X_test = dr.load_test_data(test_file)\n",
    "\n",
    "preprocess = Preprocess(X_test,sen_len,w2v_path)\n",
    "embedding = preprocess.make_embedding()\n",
    "test_x = preprocess.sentence_word2idx()\n",
    "\n",
    "\n",
    "# data loader\n",
    "test_dataset = TwitterDataset(X=test_x,y=None)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-14-f333b151611e>(17)testing()\n",
      "-> return outputs_list\n",
      "(Pdb) outputs\n",
      "tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "(Pdb) outputs_list\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f333b151611e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# model = torch.load(model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# saving results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f333b151611e>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(test_loader, model, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f333b151611e>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(test_loader, model, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def testing(test_loader, model, device):\n",
    "    outputs_list = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device,dtype=torch.long)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            outputs[outputs>=0.5] = 1\n",
    "            outputs[outputs<0.5] = 0\n",
    "            outputs_list += outputs.int().tolist()\n",
    "    return outputs_list\n",
    "\n",
    "# load model\n",
    "# model = torch.load(model_path)\n",
    "\n",
    "test_res = testing(test_loader,model,device)\n",
    "\n",
    "# saving results\n",
    "df = pd.DataFrame({'id':[i for i in range(len(test_x))],\n",
    "                  'label':test_res})\n",
    "\n",
    "print('saving result ...')\n",
    "df.to_csv('predict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
